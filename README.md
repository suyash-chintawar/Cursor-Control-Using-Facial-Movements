# Cursor-Control-Using-Facial-Movements
A very large proportion of the interfaces used in day to day life involve the use of a cursor to navigate over the screen. These interfaces necessitate the use of the hand to physically move the mouse thus moving the cursor on the screen. This requirement on the user side may not always be suitable or convenient. In an environment with restriction on motor movements, the option of having facial movements to control the interfaces becomes very useful. We propose a public transport assistance application driven with cursor control using facial gestures. The application supports checking availability of express trains, buses and local trains along with their fares between stations. The application is targeted towards users who are not in a situation to use their hands to use a cursor. This includes motor disabled people or people who may not want to touch a public interface due to hygiene concerns.

## Steps to run the project,

1. Download the dlib model from the given link, 'http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2'
2. Create a folder named 'model' if it doesn't already exists.
2. Unzip the bz2 file and add the 'shape_predictor_68_face_landmarks.dat' file to the model folder.
3. Execute the command 'python3 main.py' on the terminal.
2. Go to your browser and type 'http://localhost:5000/' to start the website.

## Contributors  
- Naveen Shenoy
- Suyash Chintawar 
- Navaneeth P